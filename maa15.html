<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Finding Linear Structure in Large Datasets with Scalable Canonical Correlation Analysis | ICML 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Finding Linear Structure in Large Datasets with Scalable Canonical Correlation Analysis">

  <meta name="citation_author" content="Ma, Zhuang">

  <meta name="citation_author" content="Lu, Yichao">

  <meta name="citation_author" content="Foster, Dean">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of The 32nd International Conference on Machine Learning">
<meta name="citation_firstpage" content="169">
<meta name="citation_lastpage" content="178">
<meta name="citation_pdf_url" content="maa15.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Finding Linear Structure in Large Datasets with Scalable Canonical Correlation Analysis</h1>

	<div id="authors">
	
		Zhuang Ma,
	
		Yichao Lu,
	
		Dean Foster
	<br />
	</div>
	<div id="info">
		Proceedings of The 32nd International Conference on Machine Learning,
		pp. 169â€“178, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Canonical Correlation Analysis (CCA) is a widely used spectral technique for finding correlation structures in multi-view datasets. In this paper, we tackle the problem of large scale CCA, where classical algorithms, usually requiring computing the product of two huge matrices and huge matrix decomposition, are computationally and storage expensive. We recast CCA from a novel perspective and propose a scalable and memory efficient <em>Augmented Approximate Gradient (AppGrad)</em> scheme for finding top <span class="math">\(k\)</span> dimensional canonical subspace which only involves large matrix multiplying a thin matrix of width <span class="math">\(k\)</span> and small matrix decomposition of dimension <span class="math">\(k\times k\)</span>. Further, <em>AppGrad</em> achieves optimal storage complexity <span class="math">\(O(k(p_1+p_2))\)</span>, compared with classical algorithms which usually require <span class="math">\(O(p_1^2+p_2^2)\)</span> space to store two dense whitening matrices. The proposed scheme naturally generalizes to stochastic optimization regime, especially efficient for huge datasets where batch algorithms are prohibitive. The online property of stochastic <em>AppGrad</em> is also well suited to the streaming scenario, where data comes sequentially. To the best of our knowledge, it is the first stochastic algorithm for CCA. Experiments on four real data sets are provided to show the effectiveness of the proposed methods.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="maa15.pdf">Download PDF</a></li>
			
			<li><a href="maa15-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
