<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Scalable Bayesian Optimization Using Deep Neural Networks | ICML 2015 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Scalable Bayesian Optimization Using Deep Neural Networks">

  <meta name="citation_author" content="Snoek, Jasper">

  <meta name="citation_author" content="Rippel, Oren">

  <meta name="citation_author" content="Swersky, Kevin">

  <meta name="citation_author" content="Kiros, Ryan">

  <meta name="citation_author" content="Satish, Nadathur">

  <meta name="citation_author" content="Sundaram, Narayanan">

  <meta name="citation_author" content="Patwary, Mostofa">

  <meta name="citation_author" content="Prabhat, Mr">

  <meta name="citation_author" content="Adams, Ryan">

<meta name="citation_publication_date" content="2015">
<meta name="citation_conference_title" content="Proceedings of The 32nd International Conference on Machine Learning">
<meta name="citation_firstpage" content="2171">
<meta name="citation_lastpage" content="2180">
<meta name="citation_pdf_url" content="snoek15.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Scalable Bayesian Optimization Using Deep Neural Networks</h1>

	<div id="authors">
	
		Jasper Snoek,
	
		Oren Rippel,
	
		Kevin Swersky,
	
		Ryan Kiros,
	
		Nadathur Satish,
	
		Narayanan Sundaram,
	
		Mostofa Patwary,
	
		Mr Prabhat,
	
		Ryan Adams
	<br />
	</div>
	<div id="info">
		Proceedings of The 32nd International Conference on Machine Learning,
		pp. 2171â€“2180, 2015
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. In this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="snoek15.pdf">Download PDF</a></li>
			
			<li><a href="snoek15-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
