---
supplementary: Supplementary:london15-supp.pdf
title: The Benefits of Learning with Strongly Convex Approximate Inference
abstract: 'We explore the benefits of strongly convex free energies in variational
  inference, providing both theoretical motivation and a new meta-algorithm. Using
  the duality between strong convexity and stability, we prove a high-probability
  bound on the error of learned marginals that is inversely proportional to the modulus
  of convexity of the free energy, thereby motivating free energies whose moduli are
  constant with respect to the size of the graph. We identify sufficient conditions
  for Î©(1)-strong convexity in two popular variational techniques: tree-reweighted
  and counting number entropies. Our insights for the latter suggest a novel counting
  number optimization framework, which guarantees strong convexity for any given modulus.
  Our experiments demonstrate that learning with a strongly convex free energy, using
  our optimization framework to guarantee a given modulus, results in substantially
  more accurate marginal probabilities, thereby validating our theoretical claims
  and the effectiveness of our framework.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: london15
month: 0
tex_title: The Benefits of Learning with Strongly Convex Approximate Inference
firstpage: 410
lastpage: 418
page: 410-418
sections: 
author:
- given: Ben
  family: London
- given: Bert
  family: Huang
- given: Lise
  family: Getoor
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/london15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
