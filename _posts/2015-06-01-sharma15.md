---
title: On Greedy Maximization of Entropy
abstract: Submodular function maximization is one of the key problems that arise in
  many machine learning tasks. Greedy selection algorithms are the proven choice to
  solve such problems, where prior theoretical work guarantees (1 - 1/e) approximation
  ratio. However, it has been empirically observed that greedy selection provides
  almost optimal solutions in practice. The main goal of this paper is to explore
  and answer why the greedy selection does significantly better than the theoretical
  guarantee of (1 - 1/e). Applications include, but are not limited to, sensor selection
  tasks which use both entropy and mutual information as a maximization criteria.
  We give a theoretical justification for the nearly optimal approximation ratio via
  detailed analysis of the curvature of these objective functions for Gaussian RBF
  kernels.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: sharma15
month: 0
firstpage: 1330
lastpage: 1338
page: 1330-1338
sections: 
author:
- given: Dravyansh
  family: Sharma
- given: Ashish
  family: Kapoor
- given: Amit
  family: Deshpande
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/sharma15/sharma15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
