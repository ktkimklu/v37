---
supplementary: Supplementary:yogatama15-supp.pdf
title: Learning Word Representations with Hierarchical Sparse Coding
abstract: We propose a new method for learning word representations using hierarchical
  regularization in sparse coding inspired by the linguistic study of word meanings.
  We show an efficient learning algorithm based on stochastic proximal methods that
  is significantly faster than previous approaches, making it possible to perform
  hierarchical sparse coding on a corpus of billions of word tokens. Experiments on
  various benchmark tasks—word similarity ranking, syntactic and semantic analogies,
  sentence completion, and sentiment analysis—demonstrate that the method outperforms
  or is competitive with state-of-the-art methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: yogatama15
month: 0
firstpage: 87
lastpage: 96
page: 87-96
sections: 
author:
- given: Dani
  family: Yogatama
- given: Manaal
  family: Faruqui
- given: Chris
  family: Dyer
- given: Noah
  family: Smith
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/yogatama15/yogatama15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
