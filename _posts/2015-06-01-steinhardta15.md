---
supplementary: Supplementary:steinhardta15-supp.zip
title: Reified Context Models
abstract: A classic tension exists between exact inference in a simple model and approximate
  inference in a complex model. The latter offers expressivity and thus accuracy,
  but the former provides coverage of the space, an important property for confidence
  estimation and learning with indirect supervision. In this work, we introduce a
  new approach, reified context models, to reconcile this tension. Specifically, we
  let the choice of factors in a graphical model (the contexts) be random variables
  inside the model itself. In this sense, the contexts are reified and can be chosen
  in a data-dependent way. Empirically, we show that our approach obtains expressivity
  and coverage on three sequence modeling tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: steinhardta15
month: 0
firstpage: 1043
lastpage: 1052
page: 1043-1052
sections: 
author:
- given: Jacob
  family: Steinhardt
- given: Percy
  family: Liang
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/steinhardta15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
