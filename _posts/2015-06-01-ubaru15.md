---
title: Low Rank Approximation using Error Correcting Coding Matrices
abstract: 'Low-rank matrix approximation is an integral component of tools such as
  principal component analysis (PCA), as well as is an important instrument used in
  applications like web search models, text mining and computer vision, e.g., face
  recognition. Recently, randomized algorithms were proposed to effectively construct
  low rank approximations of large matrices. In this paper, we show how matrices from
  error correcting codes can be used to find such low rank approximations. The benefits
  of using these code matrices are the following: (i) They are easy to generate and
  they reduce randomness significantly. (ii) Code matrices have low coherence and
  have a better chance of preserving the geometry of an entire subspace of vectors;
  (iii) Unlike Fourier transforms or Hadamard matrices, which require sampling O(k\log
  k) columns for a rank-k approximation, the log factor is not necessary in the case
  of code matrices. (iv) Under certain conditions, the approximation errors can be
  better and the singular values obtained can be more accurate, than those obtained
  using Gaussian random matrices and other structured random matrices.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: ubaru15
month: 0
tex_title: Low Rank Approximation using Error Correcting Coding Matrices
firstpage: 702
lastpage: 710
page: 702-710
sections: 
author:
- given: Shashanka
  family: Ubaru
- given: Arya
  family: Mazumdar
- given: Yousef
  family: Saad
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/ubaru15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
