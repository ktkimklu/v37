---
supplementary: Supplementary:frostig15-supp.pdf
title: 'Un-regularizing: approximate proximal point and faster stochastic algorithms
  for empirical risk minimization'
abstract: We develop a family of accelerated stochastic algorithms that optimize sums
  of convex functions. Our algorithms improve upon the fastest running time for empirical
  risk minimization (ERM), and in particular linear least-squares regression, across
  a wide range of problem settings. To achieve this, we establish a framework, based
  on the classical proximal point algorithm, useful for accelerating recent fast stochastic
  algorithms in a black-box fashion. Empirically, we demonstrate that the resulting
  algorithms exhibit notions of stability that are advantageous in practice. Both
  in theory and in practice, the provided algorithms reap the computational benefits
  of adding a large strongly convex regularization term, without incurring a corresponding
  bias to the original ERM problem.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: frostig15
month: 0
firstpage: 2540
lastpage: 2548
page: 2540-2548
sections: 
author:
- given: Roy
  family: Frostig
- given: Rong
  family: Ge
- given: Sham
  family: Kakade
- given: Aaron
  family: Sidford
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/frostig15/frostig15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
