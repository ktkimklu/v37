---
title: Unsupervised Learning of Video Representations using LSTMs
abstract: We use Long Short Term Memory (LSTM) networks to learn representations of
  video sequences. Our model uses an encoder LSTM to map an input sequence into a
  fixed length representation. This representation is decoded using single or multiple
  decoder LSTMs to perform different tasks, such as reconstructing the input sequence,
  or predicting the future sequence. We experiment with two kinds of input sequences
  – patches of image pixels and high-level representations (“percepts") of video frames
  extracted using a pretrained convolutional net. We explore different design choices
  such as whether the decoder LSTMs should condition on the generated output. We analyze
  the outputs of the model qualitatively to see how well the model can extrapolate
  the learned video representation into the future and into the past. We further evaluate
  the representations by finetuning them for a supervised learning problem – human
  action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations
  help improve classification accuracy, especially when there are only few training
  examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos)
  can help action recognition performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: srivastava15
month: 0
tex_title: Unsupervised Learning of Video Representations using LSTMs
firstpage: 843
lastpage: 852
page: 843-852
order: 843
cycles: false
author:
- given: Nitish
  family: Srivastava
- given: Elman
  family: Mansimov
- given: Ruslan
  family: Salakhudinov
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/srivastava15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
