---
supplementary: http://proceedings.mlr.press/v37/tewari15-supp.pdf
title: 'Generalization error bounds for learning to rank: Does the length of document
  lists matter?'
abstract: We consider the generalization ability of algorithms for learning to rank
  at a query level, a problem also called subset ranking. Existing generalization
  error bounds necessarily degrade as the size of the document list associated with
  a query increases. We show that such a degradation is not intrinsic to the problem.
  For several loss functions, including the cross-entropy loss used in the well known
  ListNet method, there is no degradation in generalization ability as document lists
  become longer. We also provide novel generalization error bounds under \ell_1 regularization
  and faster convergence rates if the loss function is smooth.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: tewari15
month: 0
tex_title: 'Generalization error bounds for learning to rank: Does the length of document
  lists matter?'
firstpage: 315
lastpage: 323
page: 315-323
order: 315
cycles: false
author:
- given: Ambuj
  family: Tewari
- given: Sougata
  family: Chaudhuri
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/tewari15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
