---
supplementary: Supplementary:germain15-supp.pdf
title: 'MADE: Masked Autoencoder for Distribution Estimation'
abstract: 'There has been a lot of recent interest in designing neural network models
  to estimate a distribution from a set of examples. We introduce a simple modification
  for autoencoder neural networks that yields powerful generative models. Our method
  masks the autoencoderâ€™s parameters to respect autoregressive constraints: each input
  is reconstructed only from previous inputs in a given ordering. Constrained this
  way, the autoencoder outputs can be interpreted as a set of conditional probabilities,
  and their product, the full joint probability. We can also train a single network
  that can decompose the joint probability in multiple different orderings. Our simple
  framework can be applied to multiple architectures, including deep ones. Vectorized
  implementations, such as on GPUs, are simple and fast. Experiments demonstrate that
  this approach is competitive with state-of-the-art tractable distribution estimators.
  At test time, the method is significantly faster and scales better than other autoregressive
  estimators.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: germain15
month: 0
firstpage: 881
lastpage: 889
page: 881-889
sections: 
author:
- given: Mathieu
  family: Germain
- given: Karol
  family: Gregor
- given: Iain
  family: Murray
- given: Hugo
  family: Larochelle
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/germain15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
