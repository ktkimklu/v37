---
supplementary: Supplementary:szorenyi15-supp.pdf
title: 'Qualitative Multi-Armed Bandits: A Quantile-Based Approach'
abstract: We formalize and study the multi-armed bandit (MAB) problem in a generalized
  stochastic setting, in which rewards are not assumed to be numerical. Instead, rewards
  are measured on a qualitative scale that allows for comparison but invalidates arithmetic
  operations such as averaging. Correspondingly, instead of characterizing an arm
  in terms of the mean of the underlying distribution, we opt for using a quantile
  of that distribution as a representative value. We address the problem of quantile-based
  online learning both for the case of a finite (pure exploration) and infinite time
  horizon (cumulative regret minimization). For both cases, we propose suitable algorithms
  and analyze their properties. These properties are also illustrated by means of
  first experimental studies.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: szorenyi15
month: 0
firstpage: 1660
lastpage: 1668
page: 1660-1668
sections: 
author:
- given: Balazs
  family: Szorenyi
- given: Robert
  family: Busa-Fekete
- given: Paul
  family: Weng
- given: Eyke
  family: HÃ¼llermeier
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/szorenyi15/szorenyi15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
