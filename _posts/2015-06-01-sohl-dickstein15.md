---
supplementary: Supplementary:sohl-dickstein15-supp.pdf
title: Deep Unsupervised Learning using Nonequilibrium Thermodynamics
abstract: A central problem in machine learning involves modeling complex data-sets
  using highly flexible families of probability distributions in which learning, sampling,
  inference, and evaluation are still analytically or computationally tractable. Here,
  we develop an approach that simultaneously achieves both flexibility and tractability.
  The essential idea, inspired by non-equilibrium statistical physics, is to systematically
  and slowly destroy structure in a data distribution through an iterative forward
  diffusion process. We then learn a reverse diffusion process that restores structure
  in data, yielding a highly flexible and tractable generative model of the data.
  This approach allows us to rapidly learn, sample from, and evaluate probabilities
  in deep generative models with thousands of layers or time steps, as well as to
  compute conditional and posterior probabilities under the learned model. We additionally
  release an open source reference implementation of the algorithm.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: sohl-dickstein15
month: 0
firstpage: 2256
lastpage: 2265
page: 2256-2265
sections: 
author:
- given: Jascha
  family: Sohl-Dickstein
- given: Eric
  family: Weiss
- given: Niru
  family: Maheswaranathan
- given: Surya
  family: Ganguli
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/sohl-dickstein15/sohl-dickstein15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
