---
supplementary: Supplementary:kusnera15-supp.pdf
title: Differentially Private Bayesian Optimization
abstract: Bayesian optimization is a powerful tool for fine-tuning the hyper-parameters
  of a wide variety of machine learning models. The success of machine learning has
  led practitioners in diverse real-world settings to learn classifiers for practical
  problems. As machine learning becomes commonplace, Bayesian optimization becomes
  an attractive method for practitioners to automate the process of classifier hyper-parameter
  tuning. A key observation is that the data used for tuning models in these settings
  is often sensitive. Certain data such as genetic predisposition, personal email
  statistics, and car accident history, if not properly private, may be at risk of
  being inferred from Bayesian optimization outputs. To address this, we introduce
  methods for releasing the best hyper-parameters and classifier accuracy privately.
  Leveraging the strong theoretical guarantees of differential privacy and known Bayesian
  optimization convergence bounds, we prove that under a GP assumption these private
  quantities are often near-optimal. Finally, even if this assumption is not satisfied,
  we can use different smoothness guarantees to protect privacy.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kusnera15
month: 0
firstpage: 918
lastpage: 927
page: 918-927
sections: 
author:
- given: Matt
  family: Kusner
- given: Jacob
  family: Gardner
- given: Roman
  family: Garnett
- given: Kilian
  family: Weinberger
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/kusnera15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
