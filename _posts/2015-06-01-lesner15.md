---
supplementary: Supplementary:lesner15-supp.pdf
title: Non-Stationary Approximate Modified Policy Iteration
abstract: We consider the infinite-horizon γ-discounted optimal control problem formalized
  by Markov Decision Processes. Running any instance of Modified Policy Iteration—a
  family of algorithms that can interpolate between Value and Policy Iteration—with
  an error εat each iteration is known to lead to stationary policies that are at
  least \frac2γε(1-γ)^2-optimal. Variations of Value and Policy Iteration, that build
  \ell-periodic non-stationary policies, have recently been shown to display a better
  \frac2γε(1-γ)(1-γ^\ell)-optimality guarantee. Our first contribution is to describe
  a new algorithmic scheme, Non-Stationary Modified Policy Iteration, a family of
  algorithms parameterized by two integers m \ge 0 and \ell \ge 1 that generalizes
  all the above mentionned algorithms. While m allows to interpolate between Value-Iteration-style
  and Policy-Iteration-style updates, \ell specifies the period of the non-stationary
  policy that is output. We show that this new family of algorithms also enjoys the
  improved \frac2γε(1-γ)(1-γ^\ell)-optimality guarantee. Perhaps more importantly,
  we show, by exhibiting an original problem instance, that this guarantee is tight
  for all m and \ell; this tightness was to our knowledge only proved two specific
  cases, Value Iteration (m=0,\ell=1) and Policy Iteration (m=∞,\ell=1).
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lesner15
month: 0
firstpage: 1567
lastpage: 1575
page: 1567-1575
sections: 
author:
- given: Boris
  family: Lesner
- given: Bruno
  family: Scherrer
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/lesner15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
