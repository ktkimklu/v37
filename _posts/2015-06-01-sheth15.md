---
title: Sparse Variational Inference for Generalized GP Models
abstract: Gaussian processes (GP) provide an attractive machine learning model due
  to their non-parametric form, their flexibility to capture many types of observation
  data, and their generic inference procedures. Sparse GP inference algorithms address
  the cubic complexity of GPs by focusing on a small set of pseudo-samples. To date,
  such approaches have focused on the simple case of Gaussian observation likelihoods.
  This paper develops a variational sparse solution for GPs under general likelihoods
  by providing a new characterization of the gradients required for inference in terms
  of individual observation likelihood terms. In addition, we propose a simple new
  approach for optimizing the sparse variational approximation using a fixed point
  computation. We demonstrate experimentally that the fixed point operator acts as
  a contraction in many cases and therefore leads to fast convergence. An experimental
  evaluation for count regression, classification, and ordinal regression illustrates
  the generality and advantages of the new approach.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: sheth15
month: 0
tex_title: Sparse Variational Inference for Generalized GP Models
firstpage: 1302
lastpage: 1311
page: 1302-1311
order: 1302
cycles: false
author:
- given: Rishit
  family: Sheth
- given: Yuyang
  family: Wang
- given: Roni
  family: Khardon
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/sheth15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
