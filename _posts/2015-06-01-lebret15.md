---
title: Phrase-based Image Captioning
abstract: 'Generating a novel textual description of an image is an interesting problem
  that connects computer vision and natural language processing. In this paper, we
  present a simple model that is able to generate descriptive sentences given a sample
  image. This model has a strong focus on the syntax of the descriptions. We train
  a purely linear model to embed an image representation (generated from a previously
  trained Convolutional Neural Network) into a multimodal space that is common to
  the images and the phrases that are used to described them. The system is then able
  to infer phrases from a given image sample. Based on the sentence description statistics,
  we propose a simple language model that can produce relevant descriptions for a
  given test image using the phrases inferred. Our approach, which is considerably
  simpler than state-of-the-art models, achieves comparable results in two popular
  datasets for the task: Flickr30k and the recently proposed Microsoft COCO.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lebret15
month: 0
firstpage: 2085
lastpage: 2094
page: 2085-2094
sections: 
author:
- given: Remi
  family: Lebret
- given: Pedro
  family: Pinheiro
- given: Ronan
  family: Collobert
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/lebret15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
