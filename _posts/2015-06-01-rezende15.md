---
supplementary: Supplementary:rezende15-supp.pdf
title: Variational Inference with Normalizing Flows
abstract: The choice of the approximate posterior distribution is one of the core
  problems in variational inference. Most applications of variational inference employ
  simple families of posterior approximations in order to allow for efficient inference,
  focusing on mean-field or other simple structured approximations. This restriction
  has a significant impact on the quality of inferences made using variational methods.
  We introduce a new approach for specifying flexible, arbitrarily complex and scalable
  approximate posterior distributions. Our approximations are distributions constructed
  through a normalizing flow, whereby a simple initial density is transformed into
  a more complex one by applying a sequence of invertible transformations until a
  desired level of complexity is attained. We use this view of normalizing flows to
  develop categories of finite and infinitesimal flows and provide a unified view
  of approaches for constructing rich posterior approximations. We demonstrate that
  the theoretical advantages of having posteriors that better match the true posterior,
  combined with the scalability of amortized variational approaches, provides a clear
  improvement in performance and applicability of variational inference.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: rezende15
month: 0
firstpage: 1530
lastpage: 1538
page: 1530-1538
sections: 
author:
- given: Danilo
  family: Rezende
- given: Shakir
  family: Mohamed
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/rezende15/rezende15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
