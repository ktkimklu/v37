---
supplementary: Supplementary:agarwal15-supp.pdf
title: A Lower Bound for the Optimization of Finite Sums
abstract: This paper presents a lower bound for optimizing a finite sum of n functions,
  where each function is L-smooth and the sum is μ-strongly convex. We show that no
  algorithm can reach an error εin minimizing all functions from this class in fewer
  than Ω(n + \sqrtn(κ-1)\log(1/ε)) iterations, where κ=L/μis a surrogate condition
  number. We then compare this lower bound to upper bounds for recently developed
  methods specializing to this setting. When the functions involved in this sum are
  not arbitrary, but based on i.i.d. random data, then we further contrast these complexity
  results with those for optimal first-order methods to directly optimize the sum.
  The conclusion we draw is that a lot of caution is necessary for an accurate comparison,
  and identify machine learning scenarios where the new methods help computationally.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: agarwal15
month: 0
tex_title: A Lower Bound for the Optimization of Finite Sums
firstpage: 78
lastpage: 86
page: 78-86
sections: 
author:
- given: Alekh
  family: Agarwal
- given: Leon
  family: Bottou
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/agarwal15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
