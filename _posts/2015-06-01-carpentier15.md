---
title: Simple regret for infinitely many armed bandits
abstract: 'We consider a stochastic bandit problem with infinitely many arms. In this
  setting, the learner has no chance of trying all the arms even once and has to dedicate
  its limited number of samples only to a certain number of arms. All previous algorithms
  for this setting were designed for minimizing the cumulative regret of the learner.
  In this paper, we propose an algorithm aiming at minimizing the simple regret. As
  in the cumulative regret setting of infinitely many armed bandits, the rate of the
  simple regret will depend on a parameter βcharacterizing the distribution of the
  near-optimal arms. We prove that depending on β, our algorithm is minimax optimal
  either up to a multiplicative constant or up to a \log(n) factor. We also provide
  extensions to several important cases: when βis unknown, in a natural setting where
  the near-optimal arms have a small variance, and in the case of unknown time horizon.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: carpentier15
month: 0
firstpage: 1133
lastpage: 1141
page: 1133-1141
sections: 
author:
- given: Alexandra
  family: Carpentier
- given: Michal
  family: Valko
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/carpentier15/carpentier15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
