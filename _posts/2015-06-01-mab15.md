---
supplementary: Supplementary:mab15-supp.pdf
title: Adding vs. Averaging in Distributed Primal-Dual Optimization
abstract: Distributed optimization methods for large-scale machine learning suffer
  from a communication bottleneck. It is difficult to reduce this bottleneck while
  still efficiently and accurately aggregating partial work from different machines.
  In this paper, we present a novel generalization of the recent communication-efficient
  primal-dual framework (COCOA) for distributed optimization. Our framework, COCOA+,
  allows for additive combination of local updates to the global parameters at each
  iteration, whereas previous schemes only allow conservative averaging. We give stronger
  (primal-dual) convergence rate guarantees for both COCOA as well as our new variants,
  and generalize the theory for both methods to cover non-smooth convex loss functions.
  We provide an extensive experimental comparison that shows the markedly improved
  performance of COCOA+ on several real-world distributed datasets, especially when
  scaling up the number of machines.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: mab15
month: 0
tex_title: Adding vs. Averaging in Distributed Primal-Dual Optimization
firstpage: 1973
lastpage: 1982
page: 1973-1982
sections: 
author:
- given: Chenxin
  family: Ma
- given: Virginia
  family: Smith
- given: Martin
  family: Jaggi
- given: Michael
  family: Jordan
- given: Peter
  family: Richtarik
- given: Martin
  family: Takac
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/mab15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
