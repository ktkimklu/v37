---
supplementary: Supplementary:leea15-supp.pdf
title: Distributed Box-Constrained Quadratic Optimization for Dual Linear SVM
abstract: Training machine learning models sometimes needs to be done on large amounts
  of data that exceed the capacity of a single machine, motivating recent works on
  developing algorithms that train in a distributed fashion. This paper proposes an
  efficient box-constrained quadratic optimization algorithm for distributedly training
  linear support vector machines (SVMs) with large data. Our key technical contribution
  is an analytical solution to the problem of computing the optimal step size at each
  iteration, using an efficient method that requires only O(1) communication cost
  to ensure fast convergence. With this optimal step size, our approach is superior
  to other methods by possessing global linear convergence, or, equivalently, O(\log(1/Îµ))
  iteration complexity for an epsilon-accurate solution, for distributedly solving
  the non-strongly-convex linear SVM dual problem. Experiments also show that our
  method is significantly faster than state-of- the-art distributed linear SVM algorithms
  including DSVM-AVE, DisDCA and TRON.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: leea15
month: 0
firstpage: 987
lastpage: 996
page: 987-996
sections: 
author:
- given: Ching-Pei
  family: Lee
- given: Dan
  family: Roth
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/leea15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
