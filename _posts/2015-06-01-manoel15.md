---
title: Swept Approximate Message Passing for Sparse Estimation
abstract: Approximate Message Passing (AMP) has been shown to be a superior method
  for inference problems, such as the recovery of signals from sets of noisy, lower-dimensionality
  measurements, both in terms of reconstruction accuracy and in computational efficiency.
  However, AMP suffers from serious convergence issues in contexts that do not exactly
  match its assumptions. We propose a new approach to stabilizing AMP in these contexts
  by applying AMP updates to individual coefficients rather than in parallel. Our
  results show that this change to the AMP iteration can provide theoretically expected,
  but hitherto unobtainable, performance for problems on which the standard AMP iteration
  diverges. Additionally, we find that the computational costs of this swept coefficient
  update scheme is not unduly burdensome, allowing it to be applied efficiently to
  signals of large dimensionality.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: manoel15
month: 0
tex_title: Swept Approximate Message Passing for Sparse Estimation
firstpage: 1123
lastpage: 1132
page: 1123-1132
order: 1123
cycles: false
author:
- given: Andre
  family: Manoel
- given: Florent
  family: Krzakala
- given: Eric
  family: Tramel
- given: Lenka
  family: Zdeborov√†
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/manoel15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
