---
supplementary: Supplementary:plessis15-supp.pdf
title: Convex Formulation for Learning from Positive and Unlabeled Data
abstract: We discuss binary classification from only from positive and unlabeled data
  (PU classification), which is conceivable in various real-world machine learning
  problems. Since unlabeled data consists of both positive and negative data, simply
  separating positive and unlabeled data yields a biased solution. Recently, it was
  shown that the bias can be canceled by using a particular non-convex loss such as
  the ramp loss. However, classifier training with a non-convex loss is not straightforward
  in practice. In this paper, we discuss a convex formulation for PU classification
  that can still cancel the bias. The key idea is to use different loss functions
  for positive and unlabeled samples. However, in this setup, the hinge loss is not
  permissible. As an alternative, we propose the double hinge loss. Theoretically,
  we prove that the estimators converge to the optimal solutions at the optimal parametric
  rate. Experimentally, we demonstrate that PU classification with the double hinge
  loss performs as accurate as the non-convex method, with a much lower computational
  cost.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: plessis15
month: 0
tex_title: Convex Formulation for Learning from Positive and Unlabeled Data
firstpage: 1386
lastpage: 1394
page: 1386-1394
sections: 
author:
- given: Marthinus Du
  family: Plessis
- given: Gang
  family: Niu
- given: Masashi
  family: Sugiyama
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/plessis15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
