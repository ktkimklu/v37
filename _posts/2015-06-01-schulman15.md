---
supplementary: Supplementary:schulman15-supp.pdf
title: Trust Region Policy Optimization
abstract: 'In this article, we describe a method for optimizing control policies,
  with guaranteed monotonic improvement. By making several approximations to the theoretically-justified
  scheme, we develop a practical algorithm, called Trust Region Policy Optimization
  (TRPO). This algorithm is effective for optimizing large nonlinear policies such
  as neural networks. Our experiments demonstrate its robust performance on a wide
  variety of tasks: learning simulated robotic swimming, hopping, and walking gaits;
  and playing Atari games using images of the screen as input. Despite its approximations
  that deviate from the theory, TRPO tends to give monotonic improvement, with little
  tuning of hyperparameters.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: schulman15
month: 0
firstpage: 1889
lastpage: 1897
page: 1889-1897
sections: 
author:
- given: John
  family: Schulman
- given: Sergey
  family: Levine
- given: Pieter
  family: Abbeel
- given: Michael
  family: Jordan
- given: Philipp
  family: Moritz
date: 2015-06-01
address: Lille, France
publisher: PMLR
container-title: Proceedings of the 32nd International Conference on Machine Learning
volume: '37'
genre: inproceedings
issued:
  date-parts:
  - 2015
  - 6
  - 1
pdf: http://proceedings.mlr.press/v37/schulman15/schulman15.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
